{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class='notebook_header'><b>CS 309 - Robot Learning</b></p>\n",
    "<p class='notebook_header'>Homework 1</p>\n",
    "<hr class='separate' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class='section_header'><b>Part 1: Linear Algebra</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the following matrix/vector functions using NumPy operations.\n",
    "\n",
    "If the function's operation isn't possible for matrix or vector inputs, return None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    result = np.add(a, b)\n",
    "    print(result)\n",
    "    \n",
    "def subtract(a, b):\n",
    "    result = np.subtract(a, b)\n",
    "    print(result)\n",
    "    \n",
    "def multiply(a, b):\n",
    "    result = np.dot(a, b)\n",
    "    print(result)\n",
    "    \n",
    "def divide(a, b):\n",
    "    result = np.divide(a,b)\n",
    "    print(result)\n",
    "    \n",
    "def transpose(a):\n",
    "    result = np.transpose(a)\n",
    "    print(result)\n",
    "\n",
    "def two-norm(a):\n",
    "    None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Using your code from above, solve the following equations. If an operation isn't possible, put None or comment with \"Not Possible\".</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u = \\begin{bmatrix} 2 \\\\ 3 \\\\ 9 \\end{bmatrix}, \\:\n",
    "v = \\begin{bmatrix} -2 \\\\ 1 \\\\ 8 \\end{bmatrix}\n",
    "$$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.array([\n",
    "    [2],\n",
    "    [3],\n",
    "    [9]\n",
    "])\n",
    "\n",
    "v = u = np.array([\n",
    "    [-2],\n",
    "    [1],\n",
    "    [8]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ u + v = \\begin{bmatrix} ? \\end{bmatrix} $$  \n",
    "\n",
    "$$ u - v = \\begin{bmatrix} ? \\end{bmatrix} $$  \n",
    "\n",
    "$$ u * v = \\begin{bmatrix} ? \\end{bmatrix} $$  \n",
    "\n",
    "$$ u \\div v = \\begin{bmatrix} ? \\end{bmatrix} $$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "u_plus_v = [[-4]\n",
    "            [2]\n",
    "            [16]]\n",
    "\n",
    "u_minus_v = [[0]\n",
    "            [0]\n",
    "            [0]]\n",
    "\n",
    "u_mult_v = None\n",
    "\n",
    "u_div_v = [[1.]\n",
    "          [1.]\n",
    "          [1.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ u^{\\;T} * v = \\; ? $$  \n",
    "\n",
    "$$ u * v^{\\;T} = \\begin{bmatrix} ? \\end{bmatrix} $$  \n",
    "\n",
    "$$ u^{\\;T} * u = \\; ? $$  \n",
    "\n",
    "$$ \\left \\| u \\right \\|_{2}^{2} = ? $$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "u_transpose_v = None\n",
    "\n",
    "u_v_tranpose = None\n",
    "\n",
    "u_tranpose_u = None\n",
    "\n",
    "two_norm_u = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr class='light-separate' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A = \\begin{bmatrix} 1 & 6 & 5\\\\ 0 & -4 & -1\\\\ 7 & 2 & 3 \\end{bmatrix}, \\: \n",
    "B = \\begin{bmatrix} 3 & 1 & 1\\\\ 4 & -1 & 7\\\\ 7 & 0 & 0 \\end{bmatrix}\n",
    "$$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A + B = \\begin{bmatrix} ? \\end{bmatrix} $$  \n",
    "\n",
    "$$ A - B = \\begin{bmatrix} ? \\end{bmatrix} $$  \n",
    "\n",
    "$$ A * B = \\begin{bmatrix} ? \\end{bmatrix} $$  \n",
    "\n",
    "$$ A \\div B = \\begin{bmatrix} ? \\end{bmatrix} $$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "a_plus_b = [[4 7 6]\n",
    "           [4 -5 6]\n",
    "           [14 2 3]]\n",
    "\n",
    "a_minus_b = [[-2 5 4]\n",
    "            [-4 -3 -8]\n",
    "            [0 2 3]]\n",
    "\n",
    "a_mult_b = [[62 -5 43]\n",
    "           [-23 4 -28]\n",
    "           [50 5 21]]\n",
    "\n",
    "a_div_b = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr class='light-separate' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "C = \\begin{bmatrix} 5 & 1 \\\\ -1 & 7 \\\\ 3 & 0 \\end{bmatrix}\n",
    "$$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([[5, 1],\n",
    "              [-1, 7],\n",
    "              [3, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right Pseudo Inverse of C:\n",
    "$$\n",
    "\\begin{bmatrix} ? \\end{bmatrix}\n",
    "$$  \n",
    "\n",
    "Left Pseudo Inverse of C:\n",
    "$$\n",
    "\\begin{bmatrix} ? \\end{bmatrix}\n",
    "$$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "right_pinv = None\n",
    "\n",
    "left_pinv = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr class='separate' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class='section_header'><b>Part 2: Regression</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write** the equation for Ordinary Least Squares below. \n",
    "\n",
    "**(TODO: Write Here)**\n",
    "$  \\beta\\; = (X^{T}X)^{-1}(X)^{T}y $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain** Ordinary Least Squares in terms of what it optimizes.\n",
    "\n",
    "**(TODO: Write Here)**\n",
    "It optimizes the regression by minimizing the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Don't change this cell!\n",
    "# Load in the data about the study on students\n",
    "train = np.loadtxt('train.csv', delimiter=',')\n",
    "x_0, x_1, x_2, y = train.T\n",
    "X_train = np.array([x_0, x_1, x_2]).T\n",
    "Y_train = np.expand_dims(y, 1)\n",
    "\n",
    "test = np.loadtxt('test.csv', delimiter=',')\n",
    "x_0, x_1, x_2, y = test.T\n",
    "X_test = np.array([x_0, x_1, x_2]).T\n",
    "Y_test = np.expand_dims(y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was an imaginary study done on 101 students at Crest University. The study surveyed students for the amount they have spent on electronics, books, pencils, and foods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the **amount students spend on electronics ($Y$)** is linearly related to the **amount they spend on books ($ X_{0} $), pencils ($ X_{1}$)**, and **food ($ X_{2}$)**, \n",
    "**implement** the Ordinary Least Squares method to model this regression problem.\n",
    "\n",
    "The data is read in from the previous cell code. **X_train** has the input features, while **Y_train** has corresponding target outputs.\n",
    "\n",
    "After finding a solution, try to measure the error between your predictions and the ground truth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create code for OLS here. DO NOT use any other libraries in your first implementation.\n",
    "# TODO: Plot your regression line over the input points.\n",
    "\n",
    "def OLS(X, y):\n",
    "    pass\n",
    "\n",
    "# TODO: check against training data\n",
    "theta = OLS(X_train,Y_train)\n",
    "\n",
    "# TODO: test your model on testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain** what collinearity is.\n",
    "\n",
    "**(TODO: Write Here)**\n",
    "Collinearity is when there is a relationship or association between two variables that results in skewing the data. This weakens the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write** the equation for Ridge Regression below. \n",
    "\n",
    "**(TODO: Write Here)**\n",
    "$  \\beta\\; = (X^{T}X + \\lambda\\ I )^{-1}(X)^{T}y $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain** what the purpose ridge regression and its advantages and disadvantages over OLS.\n",
    "\n",
    "**(TODO: Write Here)**\n",
    "The purpose of ridge regression is to better represent the data when there is a collinearity. OLS is not the best regression model when there is collinearity. \n",
    "Ridge Regression is advantageous because it decreases/reduces overfitting and reduces the variance. However, there could be some bias which reflects the disadvantage over OLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement** your regression model with ridge regression below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create code for Ridge Regression here. DO NOT use any other libraries\n",
    "# TODO: Plot your regression line over the input points.\n",
    "\n",
    "def RR(X, y, ridge=0.001):\n",
    "    pass\n",
    "\n",
    "# TODO: check against training data\n",
    "theta = RR(X_train,Y_train)\n",
    "\n",
    "\n",
    "# TODO: test your model on testing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain** the differences ridge regression created for theta compared to OLS, and why these differences even existed. Also try different values for the ridge parameters and describe how they effect your results.\n",
    "\n",
    "**(TODO: Write here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other regularizers other than ridge regression, such as LASSO. **Explain** the differences between LASSO and Ridge Regression and how it changes the solution mathematically.\n",
    "\n",
    "**(TODO: Write here)** \n",
    "The difference between LASSO and Ridge Regression is that in ridge, the sum of the squares of the coefficents is penalized while in LASSO, the sum of the absolute values of the coeeficients is penalized. Mathematically, high values are set to zero in LASSO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create code for LASSO here\n",
    "# TODO: Plot your regression line over the input points. \n",
    "\n",
    "def LASSO(X, y, ridge=.001):\n",
    "    pass\n",
    "\n",
    "# TODO: check against training data\n",
    "theta = LASSO(X_train,Y_train)\n",
    "\n",
    "# TODO: check against testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain** the effect elastic nets had on your values for theta compared to OLS. Also try different values for the ridge parameters and describe how they effect your results.\n",
    "\n",
    "**(TODO: Write here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain** the differences between LASSO, Ridge Regression and Elastic Nets and how it changes the solution mathematically.\n",
    "\n",
    "**(TODO: Write here)**\n",
    "Ridge Regression - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create code for Elastic Nets here. You can use a library such as scipy\n",
    "# TODO: Plot your regression line over the input points.\n",
    "\n",
    "def EN(X,y):\n",
    "    pass\n",
    "\n",
    "# TODO: check against training data\n",
    "theta = EN(X_train,Y_train)\n",
    "\n",
    "# TODO: check against testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the purpose of a regularizer?\n",
    "\n",
    "**(TODO: Write here)**\n",
    "A regularizer prevents overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give two examples where a regularizer would give more robust models.\n",
    "\n",
    "**(TODO: Write here)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain with reference to the dataset why a regularizer achieved better performance than OLS.\n",
    "\n",
    "**(TODO: Write here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr class='light-separate' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement feature transformation to fit a line to the curve generated from the .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('feature_transform.csv', delimiter=',')\n",
    "y = X[:,2].reshape(500, 1)\n",
    "X = X[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Write the lambda function phi which will transform X\n",
    "# TODO: Plot the transformation and the resulting line after transforming\n",
    "\n",
    "phi = \"fill in with lambda function\"\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:,0],y,color=(0.0,0.5,0.0))\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr class='light-separate' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall what you learned about polynomial regression and explain what is happening to the model as you increase the degrees. Run the cell below and use the slider to help you.\n",
    "\n",
    "**(TODO: Write here)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT ALTER\n",
    "\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "data = pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "data = pd.concat([data,pd.Series(boston.target,name='MEDV')],axis=1)\n",
    "\n",
    "X = data[['LSTAT']].values\n",
    "y = data['MEDV']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "temp = pd.DataFrame({'x':x_train.reshape(1, 354)[0], 'y':y_train})\n",
    "temp = temp.sort_values('x')\n",
    "x_train = temp['x'].values.reshape(354,1)\n",
    "y_train = temp['y'].values\n",
    "\n",
    "temp = pd.DataFrame({'x':x_test.reshape(1, 152)[0], 'y':y_test})\n",
    "temp = temp.sort_values('x')\n",
    "x_test = temp['x'].values.reshape(152,1)\n",
    "y_test = temp['y'].values\n",
    "\n",
    "def f(degree):\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    model.fit(x_train,y_train)\n",
    "    y_plot = model.predict(x_test)\n",
    "    \n",
    "    plt.scatter(x_train, y_train, s=10, color='red', alpha=.3)\n",
    "    plt.scatter(x_test, y_test, s=10)\n",
    "\n",
    "    test_sr = (y_test - y_plot)**2\n",
    "    test_ssr = test_sr.sum()\n",
    "    test_asr = test_ssr/len(test_sr)\n",
    "    \n",
    "    y_plot_train = model.predict(x_train)\n",
    "    train_sr = (y_train - y_plot_train)**2\n",
    "    train_ssr = train_sr.sum()\n",
    "    train_asr = train_ssr/len(train_sr)\n",
    "    \n",
    "    plt.plot(x_test, y_plot, label=\"degree %d\" % degree + '; Test Error: %.2f' % test_asr + '; Train Error: %.2f' % train_asr, color='green')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "interact(f, degree = widgets.IntSlider(min=1, max=20, step=1, value=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
